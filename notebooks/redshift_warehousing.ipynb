{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS INFRUSTRACTURE AS CODE USING PYTHON FOR REDSHIFT DW\n",
    "\n",
    "\n",
    "It is pretty simple to create and maintain few users and servers in the cloud using the provided UI but as they increase in number, it gets more cumbersome. \n",
    "\n",
    "This is where Infrustructure as Code (IaC) comes into play. IaC automates, maintains, deploy, replicate and share complex infrustructure as easily as one maintains code.\n",
    "\n",
    "In AWS, IaC can be made possible through the use of ```aws-cli SDK and Cloud Formation.``` \n",
    "\n",
    "AWS CloudFormation is a service that gives developers and businesses an easy way to create a collection of related AWS and third-party resources, and provision and manage them in an orderly and predictable fashion. It makes use of configuration files in json format providing a description of all resources, permissions, users etc\n",
    "\n",
    "For our case, weâ€™ll go the SDK way using Python to access and manage redshift and its resources. For this particular case we will create a configuration file that would provide all the necessary information to access and manage the redshift cluster already developed - ```redshift_cluster.config``` file.\n",
    "\n",
    "This file would easen the programmatic access to the cluster while we write code. Information from this file are obtained from the \"properties\" window of the redshift cluster in AWS\n",
    "\n",
    "Creating an IAM role would come handy in that, we would not need to explicitly provide the public and secret keys to facilitate communication between the aws services. We'll just use this Role.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/aws_property.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('../configs/cluster.config'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'########'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Access To the files\n",
    "config.get('AWS', 'KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECURELY ACCESSING CONFIGURATION FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('awsuser', 'Testing321', 'first-redshift-db')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEY= config.get('AWS', 'KEY')\n",
    "SECRET= config.get('AWS', 'SECRET')\n",
    "DWH_CLUSTER_TYPE=config.get('DWH', 'DWH_CLUSTER_TYPE')\n",
    "DWH_DB= config.get('DWH', 'DWH_DB')\n",
    "DWH_NUM_NODE=config.get('DWH', 'DWH_NUM_NODE')\n",
    "DWH_NODE_TYPE=config.get('DWH', 'DWH_NODE_TYPE')\n",
    "DWH_CLUSTER_IDENTIFIER=config.get('DWH', 'DWH_CLUSTER_IDENTIFIER')\n",
    "DWH_DB_USER=config.get('DWH', 'DWH_DB_USER')\n",
    "DWH_DB_PASSWORD=config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "DWH_PORT=config.get('DWH', 'DWH_PORT')\n",
    "DWH_IAM_ROLE_NAME=config.get('DWH', 'DWH_IAM_ROLE_NAME')\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KEY</td>\n",
       "      <td>########</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECRET</td>\n",
       "      <td>########</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>single-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>first-redshift-db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWN_NUM_NODE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWN_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>my-first-redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>awsuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Testing321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>redshift-s3-access-role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     param                      value\n",
       "0                      KEY                   ########\n",
       "1                   SECRET                   ########\n",
       "2         DWH_CLUSTER_TYPE                single-node\n",
       "3                   DWH_DB          first-redshift-db\n",
       "4             DWN_NUM_NODE                          1\n",
       "5            DWN_NODE_TYPE                  dc2.large\n",
       "6   DWH_CLUSTER_IDENTIFIER  my-first-redshift-cluster\n",
       "7              DWH_DB_USER                    awsuser\n",
       "8          DWH_DB_PASSWORD                 Testing321\n",
       "9                 DWH_PORT                       5439\n",
       "10       DWH_IAM_ROLE_NAME    redshift-s3-access-role"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'param':\n",
    "                ['KEY', 'SECRET', 'DWH_CLUSTER_TYPE', 'DWH_DB', 'DWN_NUM_NODE', 'DWN_NODE_TYPE','DWH_CLUSTER_IDENTIFIER', 'DWH_DB_USER', 'DWH_DB_PASSWORD', 'DWH_PORT', 'DWH_IAM_ROLE_NAME'],\n",
    "              \n",
    "              'value':\n",
    "                [KEY, SECRET, DWH_CLUSTER_TYPE, DWH_DB, DWH_NUM_NODE, DWH_NODE_TYPE,DWH_CLUSTER_IDENTIFIER, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECT TO AWS\n",
    "\n",
    "For my key and secret, I will store them in a folder ignored in this project, for security purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_config = configparser.ConfigParser()\n",
    "key_config.read_file(open('../private_config/redshift_cluster.config'))\n",
    "\n",
    "KEY = key_config.get('AWS','KEY')\n",
    "SECRET = key_config.get('AWS','SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3', \n",
    "                        region_name='us-east-2', \n",
    "                        aws_access_key_id=KEY, \n",
    "                        aws_secret_access_key=SECRET)\n",
    "\n",
    "\n",
    "iam = boto3.client('iam', \n",
    "                        region_name='us-east-2', \n",
    "                        aws_access_key_id=KEY, \n",
    "                        aws_secret_access_key=SECRET)\n",
    "\n",
    "redshift = boto3.client('redshift', \n",
    "                        region_name='us-east-2', \n",
    "                        aws_access_key_id=KEY, \n",
    "                        aws_secret_access_key=SECRET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECT TO A BUCKET AND ACCESS OBJECTS WITHIN IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean_output.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = s3.Bucket('wachira-dataeng-redshift')\n",
    "log_data_files = [filename.key for filename in bucket.objects.all()]\n",
    "log_data_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARN\n",
    "\n",
    "Amazon Resource Names (ARNs) uniquely identify AWS resources. We require an ARN when you need to specify a resource unambiguously across all of AWS, such as in IAM policies, Amazon Relational Database Service (Amazon RDS) tags, and API calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::320105466872:role/redshift-s3-access-role'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uniquely determining the rolename with the permission to access s3 buckets\n",
    "roleARN = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "roleARN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE REDSHIFT CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "            ClusterType=DWH_CLUSTER_TYPE,\n",
    "            NodeType=DWH_NODE_TYPE,\n",
    "\n",
    "            #Identifier and credentials\n",
    "            ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "            DBName=DWH_DB,\n",
    "            MasterUsername=DWH_DB_USER,\n",
    "            MasterUserPassword=DWH_DB_PASSWORD,\n",
    "\n",
    "            #Roles For s3 access\n",
    "            IamRoles=[\n",
    "                    roleARN\n",
    "                    ],\n",
    "    )\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIBE CLUSTER DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClusterIdentifier': 'my-first-redshift-cluster',\n",
       " 'NodeType': 'dc2.large',\n",
       " 'ClusterStatus': 'available',\n",
       " 'ClusterAvailabilityStatus': 'Available',\n",
       " 'MasterUsername': 'awsuser',\n",
       " 'DBName': 'first-redshift-db',\n",
       " 'Endpoint': {'Address': 'my-first-redshift-cluster.cgr5ywmtttya.us-east-2.redshift.amazonaws.com',\n",
       "  'Port': 5439},\n",
       " 'ClusterCreateTime': datetime.datetime(2023, 1, 11, 9, 27, 5, 369000, tzinfo=tzutc()),\n",
       " 'AutomatedSnapshotRetentionPeriod': 1,\n",
       " 'ManualSnapshotRetentionPeriod': -1,\n",
       " 'ClusterSecurityGroups': [],\n",
       " 'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-0c1d82624169294b3',\n",
       "   'Status': 'active'}],\n",
       " 'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "   'ParameterApplyStatus': 'in-sync'}],\n",
       " 'ClusterSubnetGroupName': 'default',\n",
       " 'VpcId': 'vpc-0b7131ad04a3a0fb3',\n",
       " 'AvailabilityZone': 'us-east-2b',\n",
       " 'PreferredMaintenanceWindow': 'sat:07:00-sat:07:30',\n",
       " 'PendingModifiedValues': {},\n",
       " 'ClusterVersion': '1.0',\n",
       " 'AllowVersionUpgrade': True,\n",
       " 'NumberOfNodes': 1,\n",
       " 'PubliclyAccessible': True,\n",
       " 'Encrypted': False,\n",
       " 'ClusterPublicKey': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDStSxB1CPlShpWHoN2n5HugUjvsPeU9pZUB0xDzxmyvmik1KV5Ac4+B3Zazme/4pIolWykyPLvxXy2v0jDaVKswtdV4YXvIGU0jUNVurbFueO4nfy7NsfJmxs71jfWGTK40qdRyND77hJZxWVE7CQDYCE4nSHKI/9uPiEVt7M0CzOHYx65eW5TPWKvmXbx3jSWaKtVMzuaTsylrVPu9EjXoVYMFRjJwbmkghw18wCKUYu70e6zO0x+jLuL2RH0gmg0lCSLiVMLneR0mEWDQc7wn42Gdo9Ft9YFAP3z5GxGEzJ5ZbtRNVAOR8mbVzhC/nhwkzlK9WuDN2PArz8Skzt7 Amazon-Redshift\\n',\n",
       " 'ClusterNodes': [{'NodeRole': 'SHARED',\n",
       "   'PrivateIPAddress': '172.31.20.76',\n",
       "   'PublicIPAddress': '3.20.150.177'}],\n",
       " 'ClusterRevisionNumber': '44903',\n",
       " 'Tags': [],\n",
       " 'EnhancedVpcRouting': False,\n",
       " 'IamRoles': [{'IamRoleArn': 'arn:aws:iam::320105466872:role/redshift-s3-access-role',\n",
       "   'ApplyStatus': 'in-sync'}],\n",
       " 'MaintenanceTrackName': 'current',\n",
       " 'DeferredMaintenanceWindows': [],\n",
       " 'NextMaintenanceWindowStartTime': datetime.datetime(2023, 1, 14, 7, 0, tzinfo=tzutc()),\n",
       " 'AvailabilityZoneRelocationStatus': 'disabled',\n",
       " 'ClusterNamespaceArn': 'arn:aws:redshift:us-east-2:320105466872:namespace:fc07622a-96c2-434d-b8ac-ffe4381a3b93',\n",
       " 'TotalStorageCapacityInMegaBytes': 400000,\n",
       " 'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "  'AquaConfigurationStatus': 'auto'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_details = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>my-first-redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>awsuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>first-redshift-db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'my-first-redshift-cluster.cgr5ywmtttya.us-east-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0b7131ad04a3a0fb3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 key  \\\n",
       "0  ClusterIdentifier   \n",
       "1           NodeType   \n",
       "2      ClusterStatus   \n",
       "3     MasterUsername   \n",
       "4             DBName   \n",
       "5           Endpoint   \n",
       "6              VpcId   \n",
       "\n",
       "                                                                                                  value  \n",
       "0                                                                             my-first-redshift-cluster  \n",
       "1                                                                                             dc2.large  \n",
       "2                                                                                             available  \n",
       "3                                                                                               awsuser  \n",
       "4                                                                                     first-redshift-db  \n",
       "5  {'Address': 'my-first-redshift-cluster.cgr5ywmtttya.us-east-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6                                                                                 vpc-0b7131ad04a3a0fb3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    keysToShow = ['ClusterIdentifier', 'NodeType', 'ClusterStatus', 'MasterUsername', 'DBName', 'Endpoint', 'ClusterStatus', 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=['key', 'value'])\n",
    "    \n",
    "prettyRedshiftProps(cluster_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster_details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTACH VPC TO THE REDSHIFT CLUSTER USING ec2 CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPC Attached to Redshift through ec2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=cluster_details['VpcId'])\n",
    "    defaultSG = list(vpc.security_groups.all())[0]\n",
    "\n",
    "    defaultSG.authorize_ingress(\n",
    "            CidrIp='0.0.0.0/0',\n",
    "            IpProtocol='TCP',\n",
    "            FromPort=int(DWH_PORT),\n",
    "            ToPort=int(DWH_PORT),\n",
    "            GroupName=defaultSG.group_name\n",
    "    )\n",
    "\n",
    "    print(\"VPC Attached to Redshift through ec2\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTING TO THE REDSHIFT DATA WAREHOUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my-first-redshift-cluster.cgr5ywmtttya.us-east-2.redshift.amazonaws.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWH_ENDPOINT = cluster_details['Endpoint']\n",
    "END_POINT = DWH_ENDPOINT['Address']\n",
    "END_POINT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    conn=psycopg2.connect(dbname = DWH_DB,\n",
    "                                    host = END_POINT, \n",
    "                                    port = 5439,\n",
    "                                    user = DWH_DB_USER,\n",
    "                                    password = 'Testing321')\n",
    "    print(\"Connected Successfully\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Redshift database\")\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Connections Using a single string for configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: \n",
    "#     conn = psycopg2.connect(f\"host={END_POINT} port={int(5439)} dbname={DWH_DB} user={DWH_DB_USER} password=Testing321\")\n",
    "#     print(\"Connected Successfully\")\n",
    "# except psycopg2.Error as e: \n",
    "#     print(\"Error: Could not make connection to the Postgres database\")\n",
    "#     print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD LOCAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>type</th>\n",
       "      <th>traveled_d</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>lon_acc</th>\n",
       "      <th>lat_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Car</td>\n",
       "      <td>48.85</td>\n",
       "      <td>9.770344</td>\n",
       "      <td>37.977391</td>\n",
       "      <td>23.737688</td>\n",
       "      <td>4.9178</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>-0.0299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>98.09</td>\n",
       "      <td>19.839417</td>\n",
       "      <td>37.977642</td>\n",
       "      <td>23.737400</td>\n",
       "      <td>16.9759</td>\n",
       "      <td>-0.0361</td>\n",
       "      <td>-0.0228</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>63.80</td>\n",
       "      <td>18.228752</td>\n",
       "      <td>37.977997</td>\n",
       "      <td>23.737264</td>\n",
       "      <td>20.1906</td>\n",
       "      <td>-0.0795</td>\n",
       "      <td>-0.3395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>145.72</td>\n",
       "      <td>26.229014</td>\n",
       "      <td>37.978135</td>\n",
       "      <td>23.737072</td>\n",
       "      <td>2.7555</td>\n",
       "      <td>-0.0302</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>138.01</td>\n",
       "      <td>24.841425</td>\n",
       "      <td>37.978134</td>\n",
       "      <td>23.737103</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id         type  traveled_d  avg_speed        lat        lon  \\\n",
       "0         1          Car       48.85   9.770344  37.977391  23.737688   \n",
       "1         2   Motorcycle       98.09  19.839417  37.977642  23.737400   \n",
       "2         3   Motorcycle       63.80  18.228752  37.977997  23.737264   \n",
       "3         4   Motorcycle      145.72  26.229014  37.978135  23.737072   \n",
       "4         5   Motorcycle      138.01  24.841425  37.978134  23.737103   \n",
       "\n",
       "     speed  lon_acc  lat_acc  time  \n",
       "0   4.9178   0.0518  -0.0299   0.0  \n",
       "1  16.9759  -0.0361  -0.0228   0.0  \n",
       "2  20.1906  -0.0795  -0.3395   0.0  \n",
       "3   2.7555  -0.0302   0.0948   0.0  \n",
       "4   0.0000   0.0000   0.0000   0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clean_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'wachira-dataeng-redshift'\n",
    "file_name = 'clean_output.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data To s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3.meta.client.upload_file(Filename='../data/final_clean.csv', Bucket=bucket_name, Key=file_name)\n",
    "    print(\"Successfully loaded data!\")\n",
    "except Exception as e:\n",
    "    print(\"Unsuccessful!!!\")\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING A TABLE IN THE REDSHIFT WAREHOUSE\n",
    "\n",
    "We can actually extract the schema of the database from the dataframe created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'name': 'index', 'type': 'integer'},\n",
       "  {'name': 'track_id', 'type': 'integer'},\n",
       "  {'name': 'type', 'type': 'string'},\n",
       "  {'name': 'traveled_d', 'type': 'number'},\n",
       "  {'name': 'avg_speed', 'type': 'number'},\n",
       "  {'name': 'lat', 'type': 'number'},\n",
       "  {'name': 'lon', 'type': 'number'},\n",
       "  {'name': 'speed', 'type': 'number'},\n",
       "  {'name': 'lon_acc', 'type': 'number'},\n",
       "  {'name': 'lat_acc', 'type': 'number'},\n",
       "  {'name': 'time', 'type': 'number'}],\n",
       " 'primaryKey': ['index'],\n",
       " 'pandas_version': '1.4.0'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.io.json.build_table_schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE clean_output(\n",
    "                    index INTEGER PRIMARY KEY,\n",
    "                    type VARCHAR,\n",
    "                    track_id VARCHAR,\n",
    "                    traveled_d FLOAT,\n",
    "                    avg_speed FLOAT,\n",
    "                    lat FLOAT,\n",
    "                    lon FLOAT,\n",
    "                    speed FLOAT,\n",
    "                    lon_acc FLOAT,\n",
    "                    lat_acc FLOAT,\n",
    "                    time FLOAT           \n",
    ");\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE CURSOR TO EXECUTE QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created table\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute(create_table)\n",
    "    print(\"Successfully created table\")\n",
    "except Exception as e:\n",
    "    print(\"Error: Problem creating the database\")\n",
    "    print(e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPY DATA FROM OUR S3 BUCKET TO THE TABLE CREATED USING THE \"COPY\" COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "COPY_CMD = \"\"\" \n",
    "COPY clean_output\n",
    "FROM 's3://wachira-dataeng-redshift/clean_output.csv'\n",
    "iam_role 'arn:aws:iam::320105466872:role/redshift-s3-access-role'\n",
    "region 'us-east-2'\n",
    "delimiter ',';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY_CMD = \"\"\" \n",
    "# COPY clean_output FROM 's3://wachira-dataeng-redshift' \n",
    "# iam_role 'arn:aws:iam::320105466872:role/redshift-s3-access-role'\n",
    "# delimiter '|';\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded from s3!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute(COPY_CMD)\n",
    "    print(\"Successfully Loaded from s3!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Loading Error\")\n",
    "    print(e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, I had some problem with using the copy command. This was because I used the data file that contained the column names as first row hence it tricky to load this data as it didn't conform to the schema's specifications i.e All the column names are in string format yet the columns are of different data types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/redshift-s3.png\" alt=\"Alternative text\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:06:46) [GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9de2cd8f42cb32e2542cbb467491be9e65e63331d655f6c7b4afb5c7d97ef756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
